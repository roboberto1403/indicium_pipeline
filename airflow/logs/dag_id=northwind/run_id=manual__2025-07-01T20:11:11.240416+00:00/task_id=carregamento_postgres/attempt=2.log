[2025-07-01T20:17:17.008+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: northwind.carregamento_postgres manual__2025-07-01T20:11:11.240416+00:00 [queued]>
[2025-07-01T20:17:17.019+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: northwind.carregamento_postgres manual__2025-07-01T20:11:11.240416+00:00 [queued]>
[2025-07-01T20:17:17.020+0000] {taskinstance.py:2170} INFO - Starting attempt 2 of 2
[2025-07-01T20:17:17.035+0000] {taskinstance.py:2191} INFO - Executing <Task(DockerOperator): carregamento_postgres> on 2025-07-01 20:11:11.240416+00:00
[2025-07-01T20:17:17.040+0000] {standard_task_runner.py:60} INFO - Started process 248 to run task
[2025-07-01T20:17:17.045+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'northwind', 'carregamento_postgres', 'manual__2025-07-01T20:11:11.240416+00:00', '--job-id', '6', '--raw', '--subdir', 'DAGS_FOLDER/northwind.py', '--cfg-path', '/tmp/tmpada15qcg']
[2025-07-01T20:17:17.051+0000] {standard_task_runner.py:88} INFO - Job 6: Subtask carregamento_postgres
[2025-07-01T20:17:17.148+0000] {task_command.py:423} INFO - Running <TaskInstance: northwind.carregamento_postgres manual__2025-07-01T20:11:11.240416+00:00 [running]> on host ba7982ddf433
[2025-07-01T20:17:17.258+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='lrbf@cin.ufpe.br' AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='northwind' AIRFLOW_CTX_TASK_ID='carregamento_postgres' AIRFLOW_CTX_EXECUTION_DATE='2025-07-01T20:11:11.240416+00:00' AIRFLOW_CTX_TRY_NUMBER='2' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-07-01T20:11:11.240416+00:00'
[2025-07-01T20:17:17.459+0000] {docker.py:359} INFO - Starting docker container from image meltano:latest
[2025-07-01T20:17:18.107+0000] {docker.py:429} INFO - Running meltano install...
[2025-07-01T20:17:20.832+0000] {docker.py:429} INFO - [2m2025-07-01T20:17:20.831251Z[0m [[32m[1minfo     [0m] [1mInstalling 7 plugins          [0m
[2025-07-01T20:17:20.841+0000] {docker.py:429} INFO - [2m2025-07-01T20:17:20.840283Z[0m [[32m[1minfo     [0m] [1mInstalling extractor 'tap-postgres'[0m
[2025-07-01T20:17:20.857+0000] {docker.py:429} INFO - [2m2025-07-01T20:17:20.857189Z[0m [[32m[1minfo     [0m] [1mInstalling extractor 'tap-csv'[0m
[2025-07-01T20:17:20.876+0000] {docker.py:429} INFO - [2m2025-07-01T20:17:20.875809Z[0m [[32m[1minfo     [0m] [1mInstalling extractor 'tap-csv-latest'[0m
[2025-07-01T20:17:20.895+0000] {docker.py:429} INFO - [2m2025-07-01T20:17:20.894533Z[0m [[32m[1minfo     [0m] [1mInstalling loader 'target-postgres'[0m
[2025-07-01T20:17:20.914+0000] {docker.py:429} INFO - [2m2025-07-01T20:17:20.913974Z[0m [[32m[1minfo     [0m] [1mInstalling loader 'target-csv'[0m
[2025-07-01T20:17:20.944+0000] {docker.py:429} INFO - [2m2025-07-01T20:17:20.943597Z[0m [[32m[1minfo     [0m] [1mInstalling loader 'target-csv-postgres'[0m
[2025-07-01T20:17:20.972+0000] {docker.py:429} INFO - [2m2025-07-01T20:17:20.971646Z[0m [[32m[1minfo     [0m] [1mInstalling loader 'target-csv-csv'[0m
[2025-07-01T20:17:23.164+0000] {docker.py:429} INFO - [2m2025-07-01T20:17:23.153379Z[0m [[32m[1minfo     [0m] [1mInstalled extractor 'tap-postgres'[0m
[2025-07-01T20:17:23.173+0000] {docker.py:429} INFO - [2m2025-07-01T20:17:23.159151Z[0m [[32m[1minfo     [0m] [1mInstalled loader 'target-postgres'[0m
[2025-07-01T20:17:28.778+0000] {docker.py:429} INFO - [2m2025-07-01T20:17:28.777851Z[0m [[32m[1minfo     [0m] [1mInstalled extractor 'tap-csv' [0m
[2025-07-01T20:17:28.781+0000] {docker.py:429} INFO - [2m2025-07-01T20:17:28.781149Z[0m [[32m[1minfo     [0m] [1mInstalled extractor 'tap-csv-latest'[0m
[2025-07-01T20:17:29.789+0000] {docker.py:429} INFO - [2m2025-07-01T20:17:29.788987Z[0m [[32m[1minfo     [0m] [1mInstalled loader 'target-csv' [0m
[2025-07-01T20:17:29.975+0000] {docker.py:429} INFO - [2m2025-07-01T20:17:29.975227Z[0m [[32m[1minfo     [0m] [1mInstalled loader 'target-csv-csv'[0m
[2025-07-01T20:17:29.979+0000] {docker.py:429} INFO - [2m2025-07-01T20:17:29.978486Z[0m [[32m[1minfo     [0m] [1mInstalled loader 'target-csv-postgres'[0m
[2025-07-01T20:17:29.979+0000] {docker.py:429} INFO - [2m2025-07-01T20:17:29.979275Z[0m [[32m[1minfo     [0m] [1mInstalled 7/7 plugins         [0m
[2025-07-01T20:17:31.979+0000] {docker.py:429} INFO - Meltano install completed. Executing command: bash -c echo '--- Conte√∫do de meltano.yml ---' && cat /opt/meltano/meltano.yml && echo '--- Fim do meltano.yml Conte√∫do ---' && echo '--- Conte√∫do de tap-csv-latest.json ---' && cat /opt/meltano/config/tap-csv-latest.json && echo '--- Fim do tap-csv-latest.json Conte√∫do ---' && meltano --log-level=debug el tap-csv-latest target-postgres
[2025-07-01T20:17:32.080+0000] {docker.py:429} INFO - --- Conte√∫do de meltano.yml ---
[2025-07-01T20:17:32.099+0000] {docker.py:429} INFO - version: 1
default_environment: dev
project_id: 27934c9d-b36b-496d-97b1-46c3823b815c
environments:
- name: dev
- name: staging
- name: prod
plugins:
  extractors:
  - name: tap-postgres
    variant: meltanolabs
    pip_url: meltanolabs-tap-postgres
    config:
      host: db_source # <--- NOME DO SERVI√áO DO SEU DB DE ORIGEM NO DOCKER COMPOSE
      port: 5432
      user: roboberto # <--- SEU USU√ÅRIO DE ORIGEM
      password: beto12345 # <--- SUA SENHA DE ORIGEM
      database: northwind # <--- SEU DB DE ORIGEM
    select:
    - public-us_states
    - public-categories
    - public-customer_demographics
    - public-customers
    - public-employee_territories
    - public-employees
    - public-orders
    - public-products
    - public-region
    - public-shippers
    - public-suppliers
    - public-territories

  - name: tap-csv
    variant: meltanolabs
    pip_url: git+https://github.com/MeltanoLabs/tap-csv.git
    config:
      files:
      - entity: order_details
        path: order_details.csv
        keys: [order_id, product_id]
        delimiter: ','
        encoding: utf-8
  - name: tap-csv-latest
    namespace: tap-csv
    variant: meltanolabs
    pip_url: git+https://github.com/MeltanoLabs/tap-csv.git
    executable: tap-csv
    # config:
    #   csv_files_definition: "/opt/meltano/config/tap-csv-latest.json"

  loaders:
  - name: target-postgres
    variant: meltanolabs
    pip_url: meltanolabs-target-postgres
    config:
      host: db_target # <--- NOME DO SERVI√áO DO SEU DB DE DESTINO NO DOCKER COMPOSE
      port: 5432
      user: postgres # <--- SEU USU√ÅRIO DE DESTINO
      password: B&t034685970 # <--- SUA SENHA DE DESTINO
      database: northwind_final # <--- SEU DB DE DESTINO
      default_target_schema: public
      dialect+driver: postgresql+psycopg2

  - name: target-csv
    variant: singer-io
    pip_url: git+https://github.com/singer-io/target-csv.git
  - name: target-csv-postgres
    namespace: target-csv-postgres
    variant: local
    pip_url: git+https://github.com/roboberto1403/target-csv-1
    config:
      destination_path: /opt/output_data/postgres
      dialect: excel
      schema: public

    after_install:
    - .meltano/loaders/target-csv-postgres/venv/bin/pip install setuptools
  - name: target-csv-csv
    namespace: target-csv-csv
    variant: local
    pip_url: git+https://github.com/roboberto1403/target-csv-2
    config:
      destination_path: /opt/output_data/csv
      dialect: excel
[2025-07-01T20:17:32.099+0000] {docker.py:429} INFO - --- Fim do meltano.yml Conte√∫do ---
--- Conte√∫do de tap-csv-latest.json ---
[2025-07-01T20:17:32.100+0000] {docker.py:429} INFO - {
  "files": [
    {
      "entity": "order_details",
      "path": "/opt/output_data/csv/order_details/2025-07-01/file.csv",
      "keys": [
        "order_id",
        "product_id"
      ],
      "delimiter": ",",
      "encoding": "utf-8"
    },
    {
      "entity": "public-categories",
      "path": "/opt/output_data/postgres/public-categories/2025-07-01/file.csv",
      "keys": [
        "category_id"
      ],
      "delimiter": ",",
      "encoding": "utf-8"
    },
    {
      "entity": "public-products",
      "path": "/opt/output_data/postgres/public-products/2025-07-01/file.csv",
      "keys": [
        "product_id"
      ],
      "delimiter": ",",
      "encoding": "utf-8"
    },
    {
      "entity": "public-suppliers",
      "path": "/opt/output_data/postgres/public-suppliers/2025-07-01/file.csv",
      "keys": [
        "supplier_id"
      ],
      "delimiter": ",",
      "encoding": "utf-8"
    },
    {
      "entity": "public-orders",
      "path": "/opt/output_data/postgres/public-orders/2025-07-01/file.csv",
      "keys": [
        "order_id"
      ],
      "delimiter": ",",
      "encoding": "utf-8"
    },
    {
      "entity": "public-customers",
      "path": "/opt/output_data/postgres/public-customers/2025-07-01/file.csv",
      "keys": [
        "customer_id"
      ],
      "delimiter": ",",
      "encoding": "utf-8"
    },
    {
      "entity": "public-employees",
      "path": "/opt/output_data/postgres/public-employees/2025-07-01/file.csv",
      "keys": [
        "employee_id"
      ],
      "delimiter": ",",
      "encoding": "utf-8"
    },
    {
      "entity": "public-employee_territories",
      "path": "/opt/output_data/postgres/public-employee_territories/2025-07-01/file.csv",
      "keys": [
        "employee_id",
        "territory_id"
      ],
      "delimiter": ",",
      "encoding": "utf-8"
    },
    {
      "entity": "public-territories",
      "path": "/opt/output_data/postgres/public-territories/2025-07-01/file.csv",
      "keys": [
        "territory_id"
      ],
      "delimiter": ",",
      "encoding": "utf-8"
    },
    {
      "entity": "public-region",
      "path": "/opt/output_data/postgres/public-region/2025-07-01/file.csv",
      "keys": [
        "region_id"
      ],
      "delimiter": ",",
      "encoding": "utf-8"
    },
    {
      "entity": "public-shippers",
      "path": "/opt/output_data/postgres/public-shippers/2025-07-01/file.csv",
      "keys": [
        "shipper_id"
      ],
      "delimiter": ",",
      "encoding": "utf-8"
    },
    {
      "entity": "public-us_states",
      "path": "/opt/output_data/postgres/public-us_states/2025-07-01/file.csv",
      "keys": [
        "state_id"
      ],
      "delimiter": ",",
      "encoding": "utf-8"
    }
  ]
}
[2025-07-01T20:17:32.100+0000] {docker.py:429} INFO - --- Fim do tap-csv-latest.json Conte√∫do ---
[2025-07-01T20:17:33.505+0000] {docker.py:429} INFO - [2m2025-07-01T20:17:33.504242Z[0m [[32m[1mdebug    [0m] [1mMeltano 3.7.9, Python 3.9.23, Linux (x86_64)[0m
[2025-07-01T20:17:33.507+0000] {docker.py:429} INFO - [2m2025-07-01T20:17:33.507063Z[0m [[32m[1mdebug    [0m] [1m/etc/timezone found, contents:
 Etc/UTC
[0m
[2025-07-01T20:17:33.507+0000] {docker.py:429} INFO - [2m2025-07-01T20:17:33.507433Z[0m [[32m[1mdebug    [0m] [1m/etc/localtime found          [0m
[2025-07-01T20:17:33.508+0000] {docker.py:429} INFO - [2m2025-07-01T20:17:33.508374Z[0m [[32m[1mdebug    [0m] [1m2 found:
 {'/etc/timezone': 'Etc/UTC', '/etc/localtime is a symlink to': 'Etc/UTC'}[0m
[2025-07-01T20:17:33.512+0000] {docker.py:429} INFO - [2m2025-07-01T20:17:33.512069Z[0m [[32m[1minfo     [0m] [1mEnvironment 'dev' is active   [0m
[2025-07-01T20:17:33.536+0000] {docker.py:429} INFO - [2m2025-07-01T20:17:33.535596Z[0m [[32m[1mdebug    [0m] [1mCreating DB engine for project at '/opt/meltano' with DB URI 'sqlite:////opt/meltano/.meltano/meltano.db'[0m
[2025-07-01T20:17:33.792+0000] {docker.py:429} INFO - [2m2025-07-01T20:17:33.791597Z[0m [[32m[1mdebug    [0m] [1mFound plugin parent           [0m [36mparent[0m=[35mtarget-postgres[0m [36mplugin[0m=[35mtarget-postgres[0m [36msource[0m=[35mLOCKFILE[0m
[2025-07-01T20:17:33.803+0000] {local_task_job_runner.py:121} ERROR - Received SIGTERM. Terminating subprocesses
[2025-07-01T20:17:33.851+0000] {process_utils.py:131} INFO - Sending 15 to group 248. PIDs of all processes in the group: [248]
[2025-07-01T20:17:33.853+0000] {process_utils.py:86} INFO - Sending the signal 15 to group 248
[2025-07-01T20:17:33.863+0000] {taskinstance.py:2450} ERROR - Received SIGTERM. Terminating subprocesses.
[2025-07-01T20:17:33.900+0000] {docker.py:521} INFO - Stopping docker container
[2025-07-01T20:17:35.210+0000] {taskinstance.py:2698} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 433, in _execute_task
    result = execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/docker/operators/docker.py", line 502, in execute
    return self._run_image()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/docker/operators/docker.py", line 376, in _run_image
    return self._run_image_with_mounts(self.mounts, add_tmp_variable=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/docker/operators/docker.py", line 426, in _run_image_with_mounts
    for log_chunk in logstream:
  File "/home/airflow/.local/lib/python3.10/site-packages/docker/types/daemon.py", line 29, in __next__
    return next(self._stream)
  File "/home/airflow/.local/lib/python3.10/site-packages/docker/api/client.py", line 428, in <genexpr>
    gen = (data for (_, data) in gen)
  File "/home/airflow/.local/lib/python3.10/site-packages/docker/utils/socket.py", line 112, in frames_iter_no_tty
    (stream, n) = next_frame_header(socket)
  File "/home/airflow/.local/lib/python3.10/site-packages/docker/utils/socket.py", line 84, in next_frame_header
    data = read_exactly(socket, 8)
  File "/home/airflow/.local/lib/python3.10/site-packages/docker/utils/socket.py", line 69, in read_exactly
    next_data = read(socket, n - len(data))
  File "/home/airflow/.local/lib/python3.10/site-packages/docker/utils/socket.py", line 40, in read
    poll.poll()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 2452, in signal_handler
    raise AirflowException("Task received SIGTERM signal")
airflow.exceptions.AirflowException: Task received SIGTERM signal
[2025-07-01T20:17:35.222+0000] {taskinstance.py:1138} INFO - Marking task as FAILED. dag_id=northwind, task_id=carregamento_postgres, execution_date=20250701T201111, start_date=20250701T201717, end_date=20250701T201735
[2025-07-01T20:17:35.306+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.10/site-packages/***/utils/email.py:154 RemovedInAirflow3Warning: Fetching SMTP credentials from configuration variables will be deprecated in a future release. Please set credentials using a connection instead.
[2025-07-01T20:17:35.307+0000] {configuration.py:1046} WARNING - section/key [smtp/smtp_user] not found in config
[2025-07-01T20:17:35.309+0000] {email.py:270} INFO - Email alerting: attempt 1
[2025-07-01T20:17:35.329+0000] {configuration.py:1046} WARNING - section/key [smtp/smtp_user] not found in config
[2025-07-01T20:17:35.329+0000] {email.py:270} INFO - Email alerting: attempt 1
[2025-07-01T20:17:35.330+0000] {taskinstance.py:826} ERROR - Failed to send email to: ['lrbf@cin.ufpe.br']
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 2334, in _run_raw_task
    self._execute_task_with_callbacks(context, test_mode, session=session)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 2499, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 2516, in _execute_task
    return _execute_task(self, context, task_orig)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 433, in _execute_task
    result = execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/docker/operators/docker.py", line 502, in execute
    return self._run_image()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/docker/operators/docker.py", line 376, in _run_image
    return self._run_image_with_mounts(self.mounts, add_tmp_variable=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/docker/operators/docker.py", line 426, in _run_image_with_mounts
    for log_chunk in logstream:
  File "/home/airflow/.local/lib/python3.10/site-packages/docker/types/daemon.py", line 29, in __next__
    return next(self._stream)
  File "/home/airflow/.local/lib/python3.10/site-packages/docker/api/client.py", line 428, in <genexpr>
    gen = (data for (_, data) in gen)
  File "/home/airflow/.local/lib/python3.10/site-packages/docker/utils/socket.py", line 112, in frames_iter_no_tty
    (stream, n) = next_frame_header(socket)
  File "/home/airflow/.local/lib/python3.10/site-packages/docker/utils/socket.py", line 84, in next_frame_header
    data = read_exactly(socket, 8)
  File "/home/airflow/.local/lib/python3.10/site-packages/docker/utils/socket.py", line 69, in read_exactly
    next_data = read(socket, n - len(data))
  File "/home/airflow/.local/lib/python3.10/site-packages/docker/utils/socket.py", line 40, in read
    poll.poll()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 2452, in signal_handler
    raise AirflowException("Task received SIGTERM signal")
airflow.exceptions.AirflowException: Task received SIGTERM signal

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 1000, in _email_alert
    send_email(task.email, subject, html_content)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/email.py", line 80, in send_email
    return backend(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/email.py", line 154, in send_email_smtp
    send_mime_email(e_from=mail_from, e_to=recipients, mime_msg=msg, conn_id=conn_id, dryrun=dryrun)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/email.py", line 272, in send_mime_email
    smtp_conn = _get_smtp_connection(smtp_host, smtp_port, smtp_timeout, smtp_ssl)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/email.py", line 316, in _get_smtp_connection
    return smtplib.SMTP(host=host, port=port, timeout=timeout)
  File "/usr/local/lib/python3.10/smtplib.py", line 255, in __init__
    (code, msg) = self.connect(host, port)
  File "/usr/local/lib/python3.10/smtplib.py", line 341, in connect
    self.sock = self._get_socket(host, port, self.timeout)
  File "/usr/local/lib/python3.10/smtplib.py", line 312, in _get_socket
    return socket.create_connection((host, port), timeout,
  File "/usr/local/lib/python3.10/socket.py", line 845, in create_connection
    raise err
  File "/usr/local/lib/python3.10/socket.py", line 833, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 824, in _handle_failure
    task_instance.email_alert(error, failure_context["task"])
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 2946, in email_alert
    _email_alert(task_instance=self, exception=exception, task=task)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 1002, in _email_alert
    send_email(task.email, subject, html_content_err)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/email.py", line 80, in send_email
    return backend(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/email.py", line 154, in send_email_smtp
    send_mime_email(e_from=mail_from, e_to=recipients, mime_msg=msg, conn_id=conn_id, dryrun=dryrun)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/email.py", line 272, in send_mime_email
    smtp_conn = _get_smtp_connection(smtp_host, smtp_port, smtp_timeout, smtp_ssl)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/email.py", line 316, in _get_smtp_connection
    return smtplib.SMTP(host=host, port=port, timeout=timeout)
  File "/usr/local/lib/python3.10/smtplib.py", line 255, in __init__
    (code, msg) = self.connect(host, port)
  File "/usr/local/lib/python3.10/smtplib.py", line 341, in connect
    self.sock = self._get_socket(host, port, self.timeout)
  File "/usr/local/lib/python3.10/smtplib.py", line 312, in _get_socket
    return socket.create_connection((host, port), timeout,
  File "/usr/local/lib/python3.10/socket.py", line 845, in create_connection
    raise err
  File "/usr/local/lib/python3.10/socket.py", line 833, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused
[2025-07-01T20:17:36.174+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 6 for task carregamento_postgres (Task received SIGTERM signal; 248)
[2025-07-01T20:17:36.205+0000] {process_utils.py:79} INFO - Process psutil.Process(pid=248, status='terminated', exitcode=1, started='20:17:16') (248) terminated with exit code 1
[2025-07-01T20:17:36.207+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 143
[2025-07-01T20:17:36.242+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
