[2025-07-01T20:28:08.524+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: northwind.carregamento_postgres manual__2025-07-01T20:22:04.964404+00:00 [queued]>
[2025-07-01T20:28:08.534+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: northwind.carregamento_postgres manual__2025-07-01T20:22:04.964404+00:00 [queued]>
[2025-07-01T20:28:08.534+0000] {taskinstance.py:2170} INFO - Starting attempt 2 of 2
[2025-07-01T20:28:08.549+0000] {taskinstance.py:2191} INFO - Executing <Task(DockerOperator): carregamento_postgres> on 2025-07-01 20:22:04.964404+00:00
[2025-07-01T20:28:08.554+0000] {standard_task_runner.py:60} INFO - Started process 243 to run task
[2025-07-01T20:28:08.564+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'northwind', 'carregamento_postgres', 'manual__2025-07-01T20:22:04.964404+00:00', '--job-id', '6', '--raw', '--subdir', 'DAGS_FOLDER/northwind.py', '--cfg-path', '/tmp/tmpzz9duac7']
[2025-07-01T20:28:08.574+0000] {standard_task_runner.py:88} INFO - Job 6: Subtask carregamento_postgres
[2025-07-01T20:28:08.682+0000] {task_command.py:423} INFO - Running <TaskInstance: northwind.carregamento_postgres manual__2025-07-01T20:22:04.964404+00:00 [running]> on host 424e77a09744
[2025-07-01T20:28:08.818+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='lrbf@cin.ufpe.br' AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='northwind' AIRFLOW_CTX_TASK_ID='carregamento_postgres' AIRFLOW_CTX_EXECUTION_DATE='2025-07-01T20:22:04.964404+00:00' AIRFLOW_CTX_TRY_NUMBER='2' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-07-01T20:22:04.964404+00:00'
[2025-07-01T20:28:08.994+0000] {docker.py:359} INFO - Starting docker container from image meltano:latest
[2025-07-01T20:28:09.634+0000] {docker.py:429} INFO - Running meltano install...
[2025-07-01T20:28:12.656+0000] {docker.py:429} INFO - [2m2025-07-01T20:28:12.653577Z[0m [[32m[1minfo     [0m] [1mInstalling 7 plugins          [0m
[2025-07-01T20:28:12.664+0000] {docker.py:429} INFO - [2m2025-07-01T20:28:12.663227Z[0m [[32m[1minfo     [0m] [1mInstalling extractor 'tap-postgres'[0m
[2025-07-01T20:28:12.683+0000] {docker.py:429} INFO - [2m2025-07-01T20:28:12.682509Z[0m [[32m[1minfo     [0m] [1mInstalling extractor 'tap-csv'[0m
[2025-07-01T20:28:12.701+0000] {docker.py:429} INFO - [2m2025-07-01T20:28:12.701088Z[0m [[32m[1minfo     [0m] [1mInstalling extractor 'tap-csv-latest'[0m
[2025-07-01T20:28:12.720+0000] {docker.py:429} INFO - [2m2025-07-01T20:28:12.720011Z[0m [[32m[1minfo     [0m] [1mInstalling loader 'target-postgres'[0m
[2025-07-01T20:28:12.747+0000] {docker.py:429} INFO - [2m2025-07-01T20:28:12.746148Z[0m [[32m[1minfo     [0m] [1mInstalling loader 'target-csv'[0m
[2025-07-01T20:28:12.776+0000] {docker.py:429} INFO - [2m2025-07-01T20:28:12.774296Z[0m [[32m[1minfo     [0m] [1mInstalling loader 'target-csv-postgres'[0m
[2025-07-01T20:28:12.803+0000] {docker.py:429} INFO - [2m2025-07-01T20:28:12.802734Z[0m [[32m[1minfo     [0m] [1mInstalling loader 'target-csv-csv'[0m
[2025-07-01T20:28:14.081+0000] {docker.py:429} INFO - [2m2025-07-01T20:28:14.080486Z[0m [[32m[1minfo     [0m] [1mInstalled loader 'target-postgres'[0m
[2025-07-01T20:28:14.084+0000] {docker.py:429} INFO - [2m2025-07-01T20:28:14.083526Z[0m [[32m[1minfo     [0m] [1mInstalled extractor 'tap-postgres'[0m
[2025-07-01T20:28:18.629+0000] {docker.py:429} INFO - [2m2025-07-01T20:28:18.628591Z[0m [[32m[1minfo     [0m] [1mInstalled extractor 'tap-csv-latest'[0m
[2025-07-01T20:28:18.752+0000] {docker.py:429} INFO - [2m2025-07-01T20:28:18.751489Z[0m [[32m[1minfo     [0m] [1mInstalled extractor 'tap-csv' [0m
[2025-07-01T20:28:19.641+0000] {docker.py:429} INFO - [2m2025-07-01T20:28:19.641149Z[0m [[32m[1minfo     [0m] [1mInstalled loader 'target-csv' [0m
[2025-07-01T20:28:19.847+0000] {docker.py:429} INFO - [2m2025-07-01T20:28:19.846877Z[0m [[32m[1minfo     [0m] [1mInstalled loader 'target-csv-postgres'[0m
[2025-07-01T20:28:19.935+0000] {docker.py:429} INFO - [2m2025-07-01T20:28:19.933864Z[0m [[32m[1minfo     [0m] [1mInstalled loader 'target-csv-csv'[0m
[2m2025-07-01T20:28:19.934122Z[0m [[32m[1minfo     [0m] [1mInstalled 7/7 plugins         [0m
[2025-07-01T20:28:20.795+0000] {docker.py:429} INFO - Meltano install completed. Executing command: bash -c echo '--- Conte√∫do de meltano.yml ---' && cat /opt/meltano/meltano.yml && echo '--- Fim do meltano.yml Conte√∫do ---' && echo '--- Conte√∫do de tap-csv-latest.json ---' && cat /opt/meltano/config/tap-csv-latest.json && echo '--- Fim do tap-csv-latest.json Conte√∫do ---' && meltano --log-level=debug el tap-csv-latest --config /opt/meltano/config/tap-csv-latest.json target-postgres
[2025-07-01T20:28:20.821+0000] {docker.py:429} INFO - --- Conte√∫do de meltano.yml ---
[2025-07-01T20:28:20.822+0000] {docker.py:429} INFO - version: 1
default_environment: dev
project_id: 27934c9d-b36b-496d-97b1-46c3823b815c
environments:
- name: dev
- name: staging
- name: prod
plugins:
  extractors:
  - name: tap-postgres
    variant: meltanolabs
    pip_url: meltanolabs-tap-postgres
    config:
      host: db_source # <--- NOME DO SERVI√áO DO SEU DB DE ORIGEM NO DOCKER COMPOSE
      port: 5432
      user: roboberto # <--- SEU USU√ÅRIO DE ORIGEM
      password: beto12345 # <--- SUA SENHA DE ORIGEM
      database: northwind # <--- SEU DB DE ORIGEM
    select:
    - public-us_states
    - public-categories
    - public-customer_demographics
    - public-customers
    - public-employee_territories
    - public-employees
    - public-orders
    - public-products
    - public-region
    - public-shippers
    - public-suppliers
    - public-territories

  - name: tap-csv
    variant: meltanolabs
    pip_url: git+https://github.com/MeltanoLabs/tap-csv.git
    config:
      files:
      - entity: order_details
        path: order_details.csv
        keys: [order_id, product_id]
        delimiter: ','
        encoding: utf-8
  - name: tap-csv-latest
    namespace: tap-csv
    variant: meltanolabs
    pip_url: git+https://github.com/MeltanoLabs/tap-csv.git
    executable: tap-csv
    # config:
    #   csv_files_definition: "/opt/meltano/config/tap-csv-latest.json"

  loaders:
  - name: target-postgres
    variant: meltanolabs
    pip_url: meltanolabs-target-postgres
    config:
      host: db_target # <--- NOME DO SERVI√áO DO SEU DB DE DESTINO NO DOCKER COMPOSE
      port: 5432
      user: postgres # <--- SEU USU√ÅRIO DE DESTINO
      password: B&t034685970 # <--- SUA SENHA DE DESTINO
      database: northwind_final # <--- SEU DB DE DESTINO
      default_target_schema: public
      dialect+driver: postgresql+psycopg2

  - name: target-csv
    variant: singer-io
    pip_url: git+https://github.com/singer-io/target-csv.git
  - name: target-csv-postgres
    namespace: target-csv-postgres
    variant: local
    pip_url: git+https://github.com/roboberto1403/target-csv-1
    config:
      destination_path: /opt/output_data/postgres
      dialect: excel
      schema: public

    after_install:
    - .meltano/loaders/target-csv-postgres/venv/bin/pip install setuptools
  - name: target-csv-csv
    namespace: target-csv-csv
    variant: local
    pip_url: git+https://github.com/roboberto1403/target-csv-2
    config:
      destination_path: /opt/output_data/csv
      dialect: excel

--- Fim do meltano.yml Conte√∫do ---
--- Conte√∫do de tap-csv-latest.json ---
[2025-07-01T20:28:20.823+0000] {docker.py:429} INFO - {
  "files": [
    {
      "entity": "order_details",
      "path": "/opt/output_data/csv/order_details/2025-07-01/file.csv",
      "keys": [
        "order_id",
        "product_id"
      ],
      "delimiter": ",",
      "encoding": "utf-8"
    },
    {
      "entity": "public-categories",
      "path": "/opt/output_data/postgres/public-categories/2025-07-01/file.csv",
      "keys": [
        "category_id"
      ],
      "delimiter": ",",
      "encoding": "utf-8"
    },
    {
      "entity": "public-products",
      "path": "/opt/output_data/postgres/public-products/2025-07-01/file.csv",
      "keys": [
        "product_id"
      ],
      "delimiter": ",",
      "encoding": "utf-8"
    },
    {
      "entity": "public-suppliers",
      "path": "/opt/output_data/postgres/public-suppliers/2025-07-01/file.csv",
      "keys": [
        "supplier_id"
      ],
      "delimiter": ",",
      "encoding": "utf-8"
    },
    {
      "entity": "public-orders",
      "path": "/opt/output_data/postgres/public-orders/2025-07-01/file.csv",
      "keys": [
        "order_id"
      ],
      "delimiter": ",",
      "encoding": "utf-8"
    },
    {
      "entity": "public-customers",
      "path": "/opt/output_data/postgres/public-customers/2025-07-01/file.csv",
      "keys": [
        "customer_id"
      ],
      "delimiter": ",",
      "encoding": "utf-8"
    },
    {
      "entity": "public-employees",
      "path": "/opt/output_data/postgres/public-employees/2025-07-01/file.csv",
      "keys": [
        "employee_id"
      ],
      "delimiter": ",",
      "encoding": "utf-8"
    },
    {
      "entity": "public-employee_territories",
      "path": "/opt/output_data/postgres/public-employee_territories/2025-07-01/file.csv",
      "keys": [
        "employee_id",
        "territory_id"
      ],
      "delimiter": ",",
      "encoding": "utf-8"
    },
    {
      "entity": "public-territories",
      "path": "/opt/output_data/postgres/public-territories/2025-07-01/file.csv",
      "keys": [
        "territory_id"
      ],
      "delimiter": ",",
      "encoding": "utf-8"
    },
    {
      "entity": "public-region",
      "path": "/opt/output_data/postgres/public-region/2025-07-01/file.csv",
      "keys": [
        "region_id"
      ],
      "delimiter": ",",
      "encoding": "utf-8"
    },
    {
      "entity": "public-shippers",
      "path": "/opt/output_data/postgres/public-shippers/2025-07-01/file.csv",
      "keys": [
        "shipper_id"
      ],
      "delimiter": ",",
      "encoding": "utf-8"
    },
    {
      "entity": "public-us_states",
      "path": "/opt/output_data/postgres/public-us_states/2025-07-01/file.csv",
      "keys": [
        "state_id"
      ],
      "delimiter": ",",
      "encoding": "utf-8"
    }
  ]
}
[2025-07-01T20:28:20.824+0000] {docker.py:429} INFO - --- Fim do tap-csv-latest.json Conte√∫do ---
[2025-07-01T20:28:21.911+0000] {docker.py:429} INFO - [2m2025-07-01T20:28:21.911180Z[0m [[32m[1mdebug    [0m] [1mMeltano 3.7.9, Python 3.9.23, Linux (x86_64)[0m
[2025-07-01T20:28:21.915+0000] {docker.py:429} INFO - [2m2025-07-01T20:28:21.914494Z[0m [[32m[1mdebug    [0m] [1m/etc/timezone found, contents:
 Etc/UTC
[0m
[2025-07-01T20:28:21.915+0000] {docker.py:429} INFO - [2m2025-07-01T20:28:21.915050Z[0m [[32m[1mdebug    [0m] [1m/etc/localtime found          [0m
[2025-07-01T20:28:21.916+0000] {docker.py:429} INFO - [2m2025-07-01T20:28:21.916086Z[0m [[32m[1mdebug    [0m] [1m2 found:
 {'/etc/timezone': 'Etc/UTC', '/etc/localtime is a symlink to': 'Etc/UTC'}[0m
[2025-07-01T20:28:21.919+0000] {docker.py:429} INFO - Usage: meltano el [OPTIONS] EXTRACTOR LOADER
Try 'meltano el --help' for help.

Error: No such option: --config
[2025-07-01T20:28:22.937+0000] {taskinstance.py:2698} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 433, in _execute_task
    result = execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/docker/operators/docker.py", line 502, in execute
    return self._run_image()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/docker/operators/docker.py", line 376, in _run_image
    return self._run_image_with_mounts(self.mounts, add_tmp_variable=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/docker/operators/docker.py", line 437, in _run_image_with_mounts
    raise DockerContainerFailedException(f"Docker container failed: {result!r}", logs=log_lines)
airflow.providers.docker.exceptions.DockerContainerFailedException: Docker container failed: {'StatusCode': 2}
[2025-07-01T20:28:22.949+0000] {taskinstance.py:1138} INFO - Marking task as FAILED. dag_id=northwind, task_id=carregamento_postgres, execution_date=20250701T202204, start_date=20250701T202808, end_date=20250701T202822
[2025-07-01T20:28:23.073+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.10/site-packages/***/utils/email.py:154 RemovedInAirflow3Warning: Fetching SMTP credentials from configuration variables will be deprecated in a future release. Please set credentials using a connection instead.
[2025-07-01T20:28:23.075+0000] {configuration.py:1046} WARNING - section/key [smtp/smtp_user] not found in config
[2025-07-01T20:28:23.075+0000] {email.py:270} INFO - Email alerting: attempt 1
[2025-07-01T20:28:23.091+0000] {configuration.py:1046} WARNING - section/key [smtp/smtp_user] not found in config
[2025-07-01T20:28:23.092+0000] {email.py:270} INFO - Email alerting: attempt 1
[2025-07-01T20:28:23.093+0000] {taskinstance.py:826} ERROR - Failed to send email to: ['lrbf@cin.ufpe.br']
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 2334, in _run_raw_task
    self._execute_task_with_callbacks(context, test_mode, session=session)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 2499, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 2516, in _execute_task
    return _execute_task(self, context, task_orig)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 433, in _execute_task
    result = execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/docker/operators/docker.py", line 502, in execute
    return self._run_image()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/docker/operators/docker.py", line 376, in _run_image
    return self._run_image_with_mounts(self.mounts, add_tmp_variable=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/docker/operators/docker.py", line 437, in _run_image_with_mounts
    raise DockerContainerFailedException(f"Docker container failed: {result!r}", logs=log_lines)
airflow.providers.docker.exceptions.DockerContainerFailedException: Docker container failed: {'StatusCode': 2}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 1000, in _email_alert
    send_email(task.email, subject, html_content)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/email.py", line 80, in send_email
    return backend(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/email.py", line 154, in send_email_smtp
    send_mime_email(e_from=mail_from, e_to=recipients, mime_msg=msg, conn_id=conn_id, dryrun=dryrun)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/email.py", line 272, in send_mime_email
    smtp_conn = _get_smtp_connection(smtp_host, smtp_port, smtp_timeout, smtp_ssl)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/email.py", line 316, in _get_smtp_connection
    return smtplib.SMTP(host=host, port=port, timeout=timeout)
  File "/usr/local/lib/python3.10/smtplib.py", line 255, in __init__
    (code, msg) = self.connect(host, port)
  File "/usr/local/lib/python3.10/smtplib.py", line 341, in connect
    self.sock = self._get_socket(host, port, self.timeout)
  File "/usr/local/lib/python3.10/smtplib.py", line 312, in _get_socket
    return socket.create_connection((host, port), timeout,
  File "/usr/local/lib/python3.10/socket.py", line 845, in create_connection
    raise err
  File "/usr/local/lib/python3.10/socket.py", line 833, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 824, in _handle_failure
    task_instance.email_alert(error, failure_context["task"])
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 2946, in email_alert
    _email_alert(task_instance=self, exception=exception, task=task)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 1002, in _email_alert
    send_email(task.email, subject, html_content_err)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/email.py", line 80, in send_email
    return backend(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/email.py", line 154, in send_email_smtp
    send_mime_email(e_from=mail_from, e_to=recipients, mime_msg=msg, conn_id=conn_id, dryrun=dryrun)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/email.py", line 272, in send_mime_email
    smtp_conn = _get_smtp_connection(smtp_host, smtp_port, smtp_timeout, smtp_ssl)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/email.py", line 316, in _get_smtp_connection
    return smtplib.SMTP(host=host, port=port, timeout=timeout)
  File "/usr/local/lib/python3.10/smtplib.py", line 255, in __init__
    (code, msg) = self.connect(host, port)
  File "/usr/local/lib/python3.10/smtplib.py", line 341, in connect
    self.sock = self._get_socket(host, port, self.timeout)
  File "/usr/local/lib/python3.10/smtplib.py", line 312, in _get_socket
    return socket.create_connection((host, port), timeout,
  File "/usr/local/lib/python3.10/socket.py", line 845, in create_connection
    raise err
  File "/usr/local/lib/python3.10/socket.py", line 833, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused
[2025-07-01T20:28:23.128+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 6 for task carregamento_postgres (Docker container failed: {'StatusCode': 2}; 243)
[2025-07-01T20:28:23.155+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2025-07-01T20:28:23.187+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
